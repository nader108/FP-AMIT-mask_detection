{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0704f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib as plt \n",
    "import numpy as np\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d30d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "init_lr = 1e-4 \n",
    "epochs = 20 \n",
    "BS = 32 \n",
    "dictory = r'D:\\engineer\\AMIT\\Face-Mask-Detection-master\\dataset'\n",
    "categories = ['with_mask' , 'without_mask']\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(dictory , category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path,img)\n",
    "        image = load_img(img_path , target_size = (224,224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d19d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform one-hot encdoing on the labels \n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype='float32')\n",
    "labels= np.array(labels)\n",
    "\n",
    "trainX , testX , trainY , testY = train_test_split(data , labels, \n",
    "                test_size = 0.20 , stratify = labels , random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061f1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentaion\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20 , \n",
    "    zoom_range= 0.15 , \n",
    "    width_shift_range= .2, \n",
    "    shear_range= .15 ,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd604ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# load the mobileNetV2\n",
    "baseModel = MobileNetV2(weights='imagenet', include_top=False, \n",
    "                       input_tensor=Input(shape=(224,224,3)))\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel = Flatten(name = 'flatten')(headModel)\n",
    "headModel = Dense(128 , activation='relu')(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2 , activation='softmax')(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input , outputs = headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e52cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 55s 553ms/step - loss: 0.4068 - accuracy: 0.8649 - val_loss: 0.1564 - val_accuracy: 0.9857\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 43s 456ms/step - loss: 0.1626 - accuracy: 0.9621 - val_loss: 0.0834 - val_accuracy: 0.9883\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 42s 439ms/step - loss: 0.1079 - accuracy: 0.9717 - val_loss: 0.0571 - val_accuracy: 0.9922\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 41s 433ms/step - loss: 0.0822 - accuracy: 0.9796 - val_loss: 0.0492 - val_accuracy: 0.9922\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 39s 407ms/step - loss: 0.0590 - accuracy: 0.9845 - val_loss: 0.0386 - val_accuracy: 0.9922\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 44s 458ms/step - loss: 0.0532 - accuracy: 0.9855 - val_loss: 0.0353 - val_accuracy: 0.9935\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 85s 896ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 84s 886ms/step - loss: 0.0484 - accuracy: 0.9865 - val_loss: 0.0326 - val_accuracy: 0.9935\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 85s 891ms/step - loss: 0.0484 - accuracy: 0.9875 - val_loss: 0.0301 - val_accuracy: 0.9935\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 84s 884ms/step - loss: 0.0369 - accuracy: 0.9895 - val_loss: 0.0343 - val_accuracy: 0.9909\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 84s 883ms/step - loss: 0.0384 - accuracy: 0.9878 - val_loss: 0.0289 - val_accuracy: 0.9935\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 85s 890ms/step - loss: 0.0392 - accuracy: 0.9888 - val_loss: 0.0282 - val_accuracy: 0.9935\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 85s 892ms/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 0.0266 - val_accuracy: 0.9948\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 85s 895ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 0.0296 - val_accuracy: 0.9909\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 85s 892ms/step - loss: 0.0268 - accuracy: 0.9924 - val_loss: 0.0283 - val_accuracy: 0.9909\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 84s 886ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 0.0297 - val_accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 85s 898ms/step - loss: 0.0285 - accuracy: 0.9918 - val_loss: 0.0266 - val_accuracy: 0.9935\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 84s 881ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.0256 - val_accuracy: 0.9948\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 84s 886ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 0.0259 - val_accuracy: 0.9948\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 85s 893ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 0.0263 - val_accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "# loop over all layers \n",
    "for layer in baseModel.layers :\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model \n",
    "\n",
    "opt = Adam(learning_rate=init_lr )\n",
    "model.compile(loss='binary_crossentropy' , optimizer = opt , \n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "# train the head of the network \n",
    "\n",
    "H = model.fit(\n",
    "    aug.flow(trainX ,trainY , batch_size=BS), \n",
    "    steps_per_epoch= len(trainX)//BS, \n",
    "    validation_data=(testX ,testY ),\n",
    "    validation_steps= len(testX)//BS, \n",
    "    epochs = epochs\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c31a2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 6s 255ms/step\n"
     ]
    }
   ],
   "source": [
    "# make prediction \n",
    "predIdxs = model.predict(testX , batch_size= BS)\n",
    "\n",
    "predIdxs = np.argmax(predIdxs , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efb8643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      0.99      0.99       383\n",
      "without_mask       0.99      0.99      0.99       384\n",
      "\n",
      "    accuracy                           0.99       767\n",
      "   macro avg       0.99      0.99      0.99       767\n",
      "weighted avg       0.99      0.99      0.99       767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show classification model\n",
    "print(classification_report(testY.argmax(axis = 1) , predIdxs , \n",
    "                           target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf2af3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving mask detection model\n"
     ]
    }
   ],
   "source": [
    "print('saving mask detection model')\n",
    "model.save(\"mask_detection_model_2\" , save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4830f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
